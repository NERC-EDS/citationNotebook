{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd532526-9061-46f7-9b11-1c194fe70cd9",
   "metadata": {},
   "source": [
    "### NERC dataset citations\n",
    "Code to collect NERC dataset citations from Scholix, CrossRef and DataCite APIs, process and merge the results.\n",
    "Produces a csv and json with details of the citations for NERC published datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a0665-00e5-4346-ace8-f733d70fbc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, json, re, datetime, os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from datetime import date\n",
    "from scholix_fun import getNERCDataDOIs, getScholixDatasetCitations, process_citation_results, getPublicationType, countScholixCitations, getCitationString\n",
    "import crossRef_fun\n",
    "from crossRef_fun import getDataCiteInfo, getCrossRefCitations, filterCrossRefResults, mergeDFs, getPublicationInfo\n",
    "from dataCite_fun import getDataCiteCitations_relationTypes, getPublicationInfo_timeCopy\n",
    "# import exportCitationResultsToCsv\n",
    "# from Results import convertCSVtoJSON\n",
    "\n",
    "\n",
    "sys.path.insert(0, '..')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31169409-3204-468d-861b-e6aea2826025",
   "metadata": {},
   "source": [
    "## Scholix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9997ffa-9db5-439e-86e0-fb036a11fed3",
   "metadata": {},
   "source": [
    "### Get the dataset DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26abbb-e936-4243-82de-b8cc8bb5c3f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this takes approx ~20 mins\n",
    "# will print output as it goes along to see progress - in JupyterLab right click on the output and select enable scrolling for outputs\n",
    "dataCite_df = getNERCDataDOIs.getNERCDataDOIs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948115f8-988e-4e3b-8250-32ce44b275cb",
   "metadata": {},
   "source": [
    "### Pass the dataset DOIs to the scholex API to get the citations and their respective DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e78b5-8db4-4d60-8124-0f2b54b38213",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this takes about 8 mins\n",
    "# prints output as it goes along to see progress - in JupyterLab right click on the output and select enable scrolling for outputs\n",
    "scholex_df = getScholixDatasetCitations.getScholixDatasetCitations(dataCite_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a64a0-e929-4873-ba6d-7b86875a2508",
   "metadata": {},
   "source": [
    "#### Process the citation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26c2f2-c7f9-489a-9c33-b67bcbead61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCite_df, scholex_df = process_citation_results.process_citation_results(dataCite_df, scholex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a4e12-f1f9-46bf-b93b-1cb47234d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out gbif registrant code prefix 10.15468\n",
    "# scholex_df = scholex_df[~scholex_df.pubID.str.contains(\"10.15468\")]\n",
    "scholex_df = scholex_df[~scholex_df['pubID'].apply(lambda x: str(x)).str.contains(\"10.15468\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdabd392-8401-4904-85ea-e396bee3b931",
   "metadata": {},
   "source": [
    "### Check the DOIs at DOI.org to determine the type of publication and to check there are no duplicates (by preprints etc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b26b099-7dee-4682-9b06-f64277d9d928",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# very long 3+ hours\n",
    "scholex_df = getPublicationType.getPublicationType(scholex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309eef8-7f15-4903-af86-58a1bc598128",
   "metadata": {},
   "source": [
    "### Output spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ec0ae-3be6-4154-a1ae-c0670e71e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "\n",
    "scholex_filename = \"Results/Intermediate data/\" + 'scholix_citation_publication_info_' + (today.strftime(\"%d%m%Y\")) + '.csv'\n",
    "scholex_df.to_csv(scholex_filename, index = False)\n",
    "scholex_df.to_csv(\"Results/Intermediate data/latest_results_scholix.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f93129-e3b9-453b-a67c-240415ffa48c",
   "metadata": {},
   "source": [
    "## CrossRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3f955-0de1-4dc8-9409-5b3eb7cf7fee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code for getting results based on a date range\n",
    "\n",
    "email = \"matnic@ceh.ac.uk\"\n",
    "prefix = \"10.5285\"\n",
    "start_date = \"1990-01-01\"\n",
    "today = date.today()\n",
    "end_date = today.strftime(\"%Y-%m-%d\")\n",
    "results_folder_path = \"Results/\"\n",
    "results_folder_path_name = results_folder_path + \"NERC_EDS_events_from_\" + start_date + \"_up_to_\" + end_date\n",
    "\n",
    "getCrossRefCitations.getCrossRefCitations_byDates(email, prefix, start_date, end_date, results_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be29100-7771-4e91-9924-047f6a29e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter results \n",
    "crossRef_df_gbif_filtered2_deduplicated = filterCrossRefResults.filterCrossRefResults(results_folder_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ed803-32cd-429f-bb9d-1b9760818697",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass citation info to datacite API to collect relevant info on the datasets, data centres etc\n",
    "(errors, dataCite_df) = getDataCiteInfo.getDataCiteInfo(crossRef_df_gbif_filtered2_deduplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8a269-20a4-4234-8256-14be2d5ed359",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset_df, crossRef_df_gbif_filtered2_deduplicated) = mergeDFs.mergeDFs(dataCite_df,crossRef_df_gbif_filtered2_deduplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a5b49-c926-41bc-89e7-7009f46ea6d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "crossRef_df_gbif_filtered2_deduplicated = getPublicationInfo.getPublicationInfo(crossRef_df_gbif_filtered2_deduplicated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4148176-e05f-4049-a2f3-c29e5e51d257",
   "metadata": {},
   "source": [
    "### Output spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcaa3a7-a2cf-41f6-90e6-faf1016578dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossRef_df_processed_filename = \"Results/Intermediate data/\" + 'dataset_citation_publication_info_' + start_date + \"_to_\" + end_date + \"_retrieved_\" + (today.strftime(\"%d%m%Y\")) + '.csv'\n",
    "crossRef_df_gbif_filtered2_deduplicated.to_csv(crossRef_df_processed_filename, index = False)\n",
    "crossRef_df_gbif_filtered2_deduplicated.to_csv(\"Results/Intermediate data/latest_results_crossRef.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39954ff-d725-4f5d-85fb-404ca48bbe44",
   "metadata": {},
   "source": [
    "## DataCite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55212a19-44c0-41c6-9bfe-57057e8f082b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "relation_type_id_list = ['is-cited-by', 'is-referenced-by', 'is-supplement-to']\n",
    "dataCite_df_relationTypes = getDataCiteCitations_relationTypes.getDataCiteCitations_relationTypes(relation_type_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951768f8-3392-4105-bedc-4cfb5824f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove http from DOI url\n",
    "doi_list = []\n",
    "for url in dataCite_df_relationTypes['subj-id']:\n",
    "    doi = url.replace('https://doi.org/','')\n",
    "    doi_list.append(doi)\n",
    "dataCite_df_relationTypes['data_doi'] = doi_list\n",
    "dataCite_df_relationTypes = dataCite_df_relationTypes.drop(['subj-id'], axis=1)\n",
    "\n",
    "# doi_list = []\n",
    "# for url in dataCite_df_relationTypes['obj-id']:\n",
    "#     doi = url.replace('https://doi.org/','')\n",
    "#     doi_list.append(doi)\n",
    "# dataCite_df_relationTypes['pub_doi'] = doi_list # rename to work in getPublicationInfo function \n",
    "    \n",
    "dataCite_df_relationTypes = dataCite_df_relationTypes.rename(columns={\"obj-id\": \"pub_doi_url\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbda5f9-4403-4a12-8b1c-11698b6e2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows where the data_doi column value does not start with \"10.5285\"\n",
    "dataCite_df_relationTypes = dataCite_df_relationTypes[dataCite_df_relationTypes['data_doi'].str.startswith('10.5285')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb96bb-c132-41ef-974d-be07cdaf898d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get dataset metadata \n",
    "info_list = []\n",
    "headers = {'client-id': 'bl.nerc'}\n",
    "api_url = 'https://api.datacite.org/dois/' \n",
    "# for doi in dataCite_df_relationTypes['data_doi']:\n",
    "for (source_id, relation_type_id, occurred_at, Page_endpoint, data_doi, pub_doi_url) in zip(dataCite_df_relationTypes['source-id'],dataCite_df_relationTypes['relation-type-id'],dataCite_df_relationTypes['occurred-at'],dataCite_df_relationTypes['Page endpoint'],dataCite_df_relationTypes['data_doi'], dataCite_df_relationTypes['pub_doi_url']):\n",
    "    r = requests.get((api_url + data_doi), headers)\n",
    "    print(r.status_code, data_doi)\n",
    "    \n",
    "    try:\n",
    "        # process author info\n",
    "        author_list = []\n",
    "        for item in r.json()['data']['attributes']['creators']:\n",
    "            author_list.append(item['name'])\n",
    "\n",
    "        info_list.append([\n",
    "            r.json()['data']['attributes']['publisher'],\n",
    "            data_doi,\n",
    "            r.json()['data']['attributes']['titles'][0]['title'],\n",
    "            author_list,\n",
    "            r.json()['data']['attributes']['publicationYear'],\n",
    "            r.json()['data']['attributes']['dates'],\n",
    "            r.json()['data']['attributes']['registered'],\n",
    "            source_id, relation_type_id, pub_doi_url, occurred_at, Page_endpoint\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        info_list.append([\"error\",data_doi,\"error\",\"error\",\"error\",\"error\",\"error\",\"error\",\"error\",pub_doi_url,\"error\",\"error\"])\n",
    "        \n",
    "columns = ['data_publisher', 'data_doi', 'data_title', 'data_authors', 'publicationYear', 'dates', 'registered', \n",
    "           'source-id', 'relation-type-id', 'pub_doi_url', 'occurred-at', 'Page endpoint']\n",
    "dataCite_df = pd.DataFrame(info_list, columns = columns)    \n",
    "print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79849fe6-9120-4b1d-9693-c60417d5dffc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get publication info - takes a long time\n",
    "dataCite_df_temp = dataCite_df.rename(columns={\"pub_doi_url\": \"subj_id\"})\n",
    "dataCite_df_publication_meta = getPublicationInfo_timeCopy.getPublicationInfo(dataCite_df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab9dde-cdf1-4fd2-b0bb-8fb772d0e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_list = []\n",
    "for url in dataCite_df_publication_meta['subj_id']:\n",
    "    doi = url.replace('https://doi.org/','')\n",
    "    doi_list.append(doi)\n",
    "dataCite_df_publication_meta['pub_doi'] = doi_list # rename to work in getPublicationInfo function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91ee3e-fa65-4817-aadb-ae9e4ec7c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process dataset publisher names\n",
    "newPublisherLst = []\n",
    "for dataCentreName in dataCite_df_publication_meta['data_publisher']:\n",
    "    if type(dataCentreName) == float or dataCentreName is None:\n",
    "        newPublisherLst.append(dataCentreName)\n",
    "        continue\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    dataCentreName_lower = dataCentreName.lower() # make it all lowercase as 'in' operator used below is case sensitive\n",
    "    if 'polar' in dataCentreName_lower:\n",
    "        newPublisherLst.append('Polar Data Centre (PDC)')\n",
    "    elif 'atmospheric' in dataCentreName_lower or 'badc' in dataCentreName_lower or 'earth' in dataCentreName_lower:\n",
    "        newPublisherLst.append('Centre for Environmental Data Analysis (CEDA)')\n",
    "    elif 'oceanographic' in dataCentreName_lower:\n",
    "        newPublisherLst.append('British Oceanographic Data Centre (BODC)')\n",
    "    elif 'geological' in dataCentreName_lower or 'geoscience' in dataCentreName_lower:\n",
    "        newPublisherLst.append('National Geoscience Data Centre (NGDC)')\n",
    "    elif 'environmental information' in dataCentreName_lower:\n",
    "        newPublisherLst.append('Environmental Information Data Centre (EIDC)')\n",
    "    elif 'environmental data' in dataCentreName_lower:\n",
    "        newPublisherLst.append('Centre for Environmental Data Analysis (CEDA)')\n",
    "    else:\n",
    "        newPublisherLst.append(dataCentreName)\n",
    "dataCite_df_publication_meta['publisher_processed'] = newPublisherLst\n",
    "\n",
    "dataCite_df_publication_meta = dataCite_df_publication_meta.drop(['data_publisher'], axis=1)\n",
    "dataCite_df_publication_meta = dataCite_df_publication_meta.rename(columns={'publisher_processed':'data_publisher'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a198c5-9183-4c2f-a562-241efcea95cb",
   "metadata": {},
   "source": [
    "### Output spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cac32e-02b8-4030-b10c-1538c108ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCite_filename = \"Results/Intermediate data/\" + 'dataCite_df_events_publication_meta_retrieved_' + (today.strftime(\"%d%m%Y\")) + '.csv'\n",
    "dataCite_df_publication_meta.to_csv(dataCite_filename, index = False)\n",
    "dataCite_df_publication_meta.to_csv(\"Results/Intermediate data/latest_results_dataCite.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c315d70-31a9-4f03-a695-4dd8ef8bc410",
   "metadata": {},
   "source": [
    "# Merge results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeaf250-b610-429a-9902-42ce787eb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataCite_filename = \"C:/Users/matnic/OneDrive/OneDrive - UKCEH/Projects/DataCentre Citations/Results/Intermediate data/dataCite_df_events_publication_meta_retrieved_19102023.csv\"\n",
    "# scholex_filename = \"C:/Users/matnic/OneDrive/OneDrive - UKCEH/Projects/DataCentre Citations/Results/Intermediate data/scholix_citation_publication_info_19102023.csv\"\n",
    "# crossRef_df_processed_filename = \"C:/Users/matnic/OneDrive/OneDrive - UKCEH/Projects/DataCentre Citations/Results/Intermediate data/dataset_citation_publication_info_1990-01-01_to_2023-10-19_retrieved_19102023.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ede1e-b0c8-49ef-b91f-c6e807f2c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scholex_df = pd.read_csv(scholex_filename)\n",
    "crossref_df = pd.read_csv(crossRef_df_processed_filename)\n",
    "datacite_df = pd.read_csv(dataCite_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a675c8f-ed5c-4f06-baeb-1d22f1cdbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacite_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cafe38-fb81-4777-a44d-394b3d17affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove https bits from crossref df DOIs\n",
    "# remove url bit from subj_id\n",
    "crossref_doi_list = []\n",
    "for url in crossref_df['subj_id']:\n",
    "    doi = url.replace('https://doi.org/','')\n",
    "    crossref_doi_list.append(doi)\n",
    "crossref_df['subj_doi'] = crossref_doi_list\n",
    "\n",
    "# remove url bit from 'obj_id'\n",
    "crossref_doi_list = []\n",
    "for url in crossref_df['obj_id']:\n",
    "    temp = url.split('/')\n",
    "    crossref_doi_list.append(temp[3] + \"/\" + temp[4])\n",
    "crossref_df['obj_doi'] = crossref_doi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78220b50-fd3f-45c3-a191-ab2b05531786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the three dataframes make columns match\n",
    "# columns should be:\n",
    "# can add event_source, dates, publication_publisher columns later\n",
    "newColumns = ['data_publisher', 'data_doi', 'data_title', 'data_authors', 'relation_type_id', 'publication_doi', 'publication_type', 'publication_title', 'publication_authors']\n",
    "\n",
    "crossref_column_list = [crossref_df['dataset_publisher_processed'],crossref_df['obj_doi'],crossref_df['dataset_Title'],crossref_df['dataset_authors'],crossref_df['relation_type_id'],crossref_df['subj_doi'],crossref_df['subj_work_type_id'],crossref_df['pub_Title'],crossref_df['pub_authors']]\n",
    "crossref_df_newColumns = pd.concat(crossref_column_list, axis = 1)\n",
    "crossref_df_newColumns.columns = newColumns\n",
    "\n",
    "# scholex_column_list = [scholex_df[['datasetPublisher']],scholex_df[['datasetDOI']],scholex_df[['datasetTitle']],scholex_df[['datasetAuthors_processed']],scholex_df[['relationshipType']],scholex_df[['pubID']],scholex_df[['PubType']],scholex_df[['pubTitle']],scholex_df[['pubAuthors_processed']]]\n",
    "scholex_column_list = [scholex_df['datasetPublisher'],scholex_df['datasetDOI'],scholex_df['datasetTitle'],scholex_df['datasetAuthors'],scholex_df['relationshipType'],scholex_df['pubID'],scholex_df['PubType'],scholex_df['pubTitle'],scholex_df['pubAuthors_processed']]\n",
    "scholex_df_newColumns = pd.concat(scholex_column_list, axis = 1)\n",
    "scholex_df_newColumns.columns = newColumns\n",
    "\n",
    "datacite_column_list = [datacite_df['data_publisher'], datacite_df['data_doi'], datacite_df['data_title'], datacite_df['data_authors'], datacite_df['relation-type-id'], datacite_df['pub_doi'], datacite_df['publisher'], datacite_df['pub_Title'], datacite_df['pub_authors']] \n",
    "datacite_df_newColumns = pd.concat(datacite_column_list, axis = 1)\n",
    "datacite_df_newColumns.columns = newColumns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81067cd-b3a0-4c8d-9b02-93c0ec3f64ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create single list of data dois \n",
    "scholix_doi_list = list(scholex_df_newColumns['data_doi'])\n",
    "crossref_doi_list = list(crossref_df_newColumns['data_doi'])\n",
    "datacite_doi_list = list(datacite_df_newColumns['data_doi'])\n",
    "\n",
    "data_doi_list = scholix_doi_list + crossref_doi_list + datacite_doi_list\n",
    "\n",
    "# remove duplicates = convert to dict and back to list again auto removes dups\n",
    "data_doi_list_unique = list( dict.fromkeys(data_doi_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd101804-5fc2-42ea-8f17-ceeeff55d6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop through list of data dois, check pub DOI in each of crossref scholex and datacite dfs - compare result\n",
    "comparison_dicts = []\n",
    "data_doi_df = pd.DataFrame(data_doi_list_unique)\n",
    "for doi in data_doi_df[0]:\n",
    "    doi = doi.replace(\")\",\"\") # remove rogue brackets\n",
    "    scholex_indices = scholex_df_newColumns[scholex_df_newColumns.data_doi.str.match(doi)].index\n",
    "    scholex_matches = scholex_df_newColumns['publication_doi'].iloc[scholex_indices].tolist()\n",
    "    \n",
    "    crossref_indices = crossref_df_newColumns[crossref_df_newColumns.data_doi.str.match(doi)].index\n",
    "    crossref_matches = crossref_df_newColumns['publication_doi'].iloc[crossref_indices].tolist()\n",
    "    \n",
    "    datacite_indices = datacite_df_newColumns[datacite_df_newColumns.data_doi.str.match(doi)].index\n",
    "    datacite_matches = datacite_df_newColumns['publication_doi'].iloc[datacite_indices].tolist()\n",
    "    \n",
    "    combined = scholex_matches + crossref_matches + datacite_matches\n",
    "    combined_unique = list(dict.fromkeys(combined))\n",
    "    \n",
    "    inScholix_notIn_crossRef = list(set(scholex_matches) - set(crossref_matches))\n",
    "    inCrossRef_notIn_scholix = list(set(crossref_matches) - set(scholex_matches))\n",
    "    inDatacite_notIn_scholix_or_crossRef = list(set(datacite_matches) - set(scholex_matches) - set(crossref_matches))\n",
    "    \n",
    "    comparison_dicts.append({\n",
    "        'data_doi': doi,\n",
    "        'combined_unique_dois': combined_unique,\n",
    "        'scholex_pub_dois': scholex_matches,\n",
    "        'crossref_pub_dois': crossref_matches,\n",
    "        'datacite_pub_dois': datacite_matches,\n",
    "        'inScholix_notIn_crossRef':inScholix_notIn_crossRef,\n",
    "        'inCrossRef_notIn_scholix':inCrossRef_notIn_scholix,\n",
    "        'inDatacite_notIn_scholix_or_crossRef':inDatacite_notIn_scholix_or_crossRef\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c62d5-71a2-470a-b2b9-9d0076f29cc1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for combined_unique_dois create a final dataframe getting metadata  from dfs\n",
    "results = []\n",
    "for dataset in comparison_dicts:\n",
    "    for pubdoi in dataset['scholex_pub_dois']:\n",
    "        \n",
    "        # find index of this pubdoi datadoi pair in scholex_df\n",
    "        pub_indices = scholex_df_newColumns[scholex_df_newColumns.publication_doi.str.match(pubdoi)].index\n",
    "        data_indices = scholex_df_newColumns[scholex_df_newColumns.data_doi.str.match(dataset['data_doi'])].index\n",
    "        try:\n",
    "            index = list((set(pub_indices) & set(data_indices)))[0]\n",
    "        except Exception as e:\n",
    "            print(\"scholex_pub_dois\")\n",
    "            print(\"pub_indices: \", pub_indices, \"data_indices: \", data_indices)\n",
    "            print(json.dumps(dataset, indent=2))\n",
    "            continue\n",
    "        \n",
    "        results.append({\n",
    "            'data_Publisher': scholex_df_newColumns.iloc[index]['data_publisher'],\n",
    "            'data_doi':dataset['data_doi'],\n",
    "            'data_Title': scholex_df_newColumns.iloc[index]['data_title'],\n",
    "            'data_Authors': scholex_df_newColumns.iloc[index]['data_authors'],\n",
    "            'relation_type_id': scholex_df_newColumns.iloc[index]['relation_type_id'],\n",
    "            'publication_doi':pubdoi,\n",
    "            'publication_type': scholex_df_newColumns.iloc[index]['publication_type'],\n",
    "            'publication_title': scholex_df_newColumns.iloc[index]['publication_title'],\n",
    "            'publication_authors': scholex_df_newColumns.iloc[index]['publication_authors'],\n",
    "            'citation_event_source': 'Scholix'\n",
    "            })\n",
    "  \n",
    "    \n",
    "    for pubdoi in dataset['inCrossRef_notIn_scholix']:\n",
    "        # find index of this pubdoi datadoi pair in crossref_df\n",
    "        pub_indices = crossref_df_newColumns[crossref_df_newColumns.publication_doi.str.match(pubdoi)].index\n",
    "        data_indices = crossref_df_newColumns[crossref_df_newColumns.data_doi.str.match(dataset['data_doi'])].index\n",
    "        try:\n",
    "            index = list((set(pub_indices) & set(data_indices)))[0]\n",
    "        except Exception as e:\n",
    "            print(\"inCrossRef_notIn_scholix\")\n",
    "            print(\"pub_indices: \", pub_indices, \"data_indices: \", data_indices)\n",
    "            print(json.dumps(dataset, indent=2))\n",
    "            continue\n",
    "        \n",
    "        results.append({\n",
    "            'data_Publisher': crossref_df_newColumns.iloc[index]['data_publisher'],\n",
    "            'data_doi':dataset['data_doi'],\n",
    "            'data_Title': crossref_df_newColumns.iloc[index]['data_title'],\n",
    "            'data_Authors': crossref_df_newColumns.iloc[index]['data_authors'],\n",
    "            'relation_type_id': crossref_df_newColumns.iloc[index]['relation_type_id'],\n",
    "            'publication_doi':pubdoi,\n",
    "            'publication_type': crossref_df_newColumns.iloc[index]['publication_type'],\n",
    "            'publication_title': crossref_df_newColumns.iloc[index]['publication_title'],\n",
    "            'publication_authors': crossref_df_newColumns.iloc[index]['publication_authors'],\n",
    "            'citation_event_source': 'CrossRef'\n",
    "            })\n",
    "        \n",
    "        \n",
    "    for pubdoi in dataset['inDatacite_notIn_scholix_or_crossRef']:\n",
    "        # find index of this pubdoi datadoi pair in datacite_df_newColumns\n",
    "        pub_indices = datacite_df_newColumns[datacite_df_newColumns.publication_doi.str.match(pubdoi)].index\n",
    "        data_indices = datacite_df_newColumns[datacite_df_newColumns.data_doi.str.match(dataset['data_doi'])].index\n",
    "        try:\n",
    "            index = list((set(pub_indices) & set(data_indices)))[0]\n",
    "        except Exception as e:\n",
    "            print(\"inDatacite_notIn_scholix_or_crossRef\")\n",
    "            print(\"pub_indices: \", pub_indices, \"data_indices: \", data_indices)\n",
    "            print(json.dumps(dataset, indent=2))\n",
    "            continue\n",
    "        \n",
    "        results.append({\n",
    "            'data_Publisher': datacite_df_newColumns.iloc[index]['data_publisher'],\n",
    "            'data_doi':dataset['data_doi'],\n",
    "            'data_Title': datacite_df_newColumns.iloc[index]['data_title'],\n",
    "            'data_Authors': datacite_df_newColumns.iloc[index]['data_authors'],\n",
    "            'relation_type_id': datacite_df_newColumns.iloc[index]['relation_type_id'],\n",
    "            'publication_doi':pubdoi,\n",
    "            'publication_type': datacite_df_newColumns.iloc[index]['publication_type'],\n",
    "            'publication_title': datacite_df_newColumns.iloc[index]['publication_title'],\n",
    "            'publication_authors': datacite_df_newColumns.iloc[index]['publication_authors'],\n",
    "            'citation_event_source': 'DataCite'\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b49aa-e88a-4258-a8b2-abe533e6dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_citations = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943c10e-fa74-4db8-8c0e-c3916b4adfe1",
   "metadata": {},
   "source": [
    "### Get the citation string (APA format) of the publication that has cited the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f32daf-a1d4-4e62-99b8-1a93035fe03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TAKES A LONG TIME - hours\n",
    "# citationStrList = [] # create an empty list in which to put the citation strings\n",
    "\n",
    "# for pubDOI in data_citations['publication_doi']:\n",
    "#     if pubDOI.startswith('10.'):\n",
    "#         r = requests.get(('https://doi.org/' + pubDOI), headers={\"Accept\": \"text/x-bibliography\", \"style\": \"apa\", \"Accept-Charset\": \"utf-8\"})\n",
    "#         #print(r.status_code)\n",
    "#         citationStrList.append(r.text) # add the citation strings to the list\n",
    "#     else:\n",
    "#         citationStrList.append('not a doi')\n",
    "    \n",
    "# data_citations['PubCitationStr'] = citationStrList # add the citation string list to the Scholex df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91743818-39bd-4c22-8247-70a22ecd0a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf029b-f746-4cf5-a268-da7016e3b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "citationStrList = [] # create an empty list in which to put the citation strings\n",
    "\n",
    "for pubDOI in data_citations['publication_doi']:\n",
    "    if pubDOI.startswith('10.'):\n",
    "        print(pubDOI)\n",
    "        r = requests.get((\"https://citation.crosscite.org/format?style=frontiers-of-biogeography&lang=en-GB&doi=\" + pubDOI), headers={\"Accept\":\"text/x-bibliography\", \"Accept-Charset\": \"utf-8\"})\n",
    "        print(r.status_code)\n",
    "        encoded_citation = r.text\n",
    "        # add the citation strings to the list and Decode the author names assuming UTF-8 encoding\n",
    "        citationStrList.append(encoded_citation.encode('latin1').decode('utf-8')) \n",
    "    else:\n",
    "        citationStrList.append('not a doi')\n",
    "        \n",
    "data_citations['PubCitationStr'] = citationStrList # add the citation string list to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4512ee-51a8-4403-b5f8-f2b77ffe82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra requested columns\n",
    "data_citations['data_doi_url'] = 'doi.org/' + data_citations['data_doi']\n",
    "data_citations['publication_doi_url'] = 'doi.org/' + data_citations['publication_doi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fe4ef-abc4-44ab-b207-3adec24c9a09",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "datacite_df2 = datacite_df[['data_doi', 'publicationYear']]\n",
    "data_citations_merged = data_citations.merge(datacite_df2, left_on='data_doi', right_on='data_doi', how='left')\n",
    "data_citations_merged['publicationYear'] = data_citations_merged['publicationYear'].astype('Int64')\n",
    "data_citations_merged = data_citations_merged.fillna(np.nan).replace([np.nan], [None])\n",
    "\n",
    "data_citations_merged = data_citations_merged.drop_duplicates(subset=['data_doi', 'publication_doi'])\n",
    "# data_citations_merged\n",
    "data_citations = data_citations_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4735b5-0244-4374-918b-ba9cf9fb2921",
   "metadata": {},
   "source": [
    "## Output json and csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e4cac-93fe-4cff-b648-99056322d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output csv file\n",
    "today = date.today()\n",
    "\n",
    "results_folder_path = \"Results/v2/\"\n",
    "file_name = 'dataCitations_allSourcesMerged_retrieved_' + (today.strftime(\"%d%m%Y\"))\n",
    "\n",
    "data_citations_csvfilename = results_folder_path + file_name + '.csv'\n",
    "data_citations.to_csv(data_citations_csvfilename, index = False)\n",
    "print(data_citations_csvfilename)\n",
    "\n",
    "# write data to 'latest_results' csv file\n",
    "latest_file_name = results_folder_path + 'latest_results' + '.csv'\n",
    "data_citations.to_csv(latest_file_name, index = False)\n",
    "\n",
    "\n",
    "# write data to 'latest_results' json file with data publisher as top level key\n",
    "latest_file_name_json = results_folder_path + 'latest_results' + '.json'\n",
    "\n",
    "# Group by 'data_Publisher' and convert the DataFrame to a nested dictionary\n",
    "nested_dict = data_citations.groupby('data_Publisher').apply(\n",
    "    lambda x: x.drop('data_Publisher', axis=1).to_dict(orient='records')\n",
    ").to_dict()\n",
    "\n",
    "# Convert the nested dictionary to a JSON object\n",
    "import json\n",
    "json_object = json.dumps(nested_dict)\n",
    "\n",
    "# Save the JSON object to a file\n",
    "with open(latest_file_name_json, 'w') as f:\n",
    "    f.write(json_object)\n",
    "    \n",
    "data_citations_jsonfilename = results_folder_path + file_name + '.json'\n",
    "\n",
    "with open(data_citations_jsonfilename, 'w') as f:\n",
    "    f.write(json_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96075c8b-07e5-4771-9698-bd1394e706a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e373d5-4818-4cd7-9ee0-e24c35b8845f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5da55c4d-c1e1-49a0-aab3-32d5d54bc722",
   "metadata": {},
   "source": [
    "## Extra cells useful for development, not for use in collecting the citation info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd0e23-72e2-4312-b685-a764b0637302",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Read the JSON file into a pandas DataFrame\n",
    "# results_folder_path = \"C:/Users/matnic/OneDrive/OneDrive - UKCEH/Projects/DataCentre Citations/Results/v2/\"\n",
    "# latest_file_name_json = results_folder_path + 'latest_results' + '.json'\n",
    "\n",
    "# with open(latest_file_name_json, 'r') as f:\n",
    "#     json_data = json.load(f)\n",
    "\n",
    "# # Convert the nested dictionary back into a DataFrame\n",
    "# records = []\n",
    "# for publisher, data_list in json_data.items():\n",
    "#     for data_dict in data_list:\n",
    "#         data_dict['data_Publisher'] = publisher\n",
    "#         records.append(data_dict)\n",
    "\n",
    "# data_citations = pd.DataFrame.from_records(records)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# data_citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba180586-7084-496a-99db-97ba79e261e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check pub title info not given results\n",
    "# result = data_citations[data_citations['publication_title'] == 'Info not given']\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1bdc30-93f8-46ee-8372-ca362a73711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result['citation_event_source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b8c2e-f292-454c-9b6e-ac590ccd79ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522d283-dcf7-4b82-b778-bd5e3d8778f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload  # Python 3.4+\n",
    "# reload(getPublicationInfo_timeCopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1f429-7cd9-474b-9c50-85ff7694161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # Saving the objects:\n",
    "# with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "#     pickle.dump([dataCite_df, scholex_df], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca83bd-08fe-42b7-bf9f-9594eac7024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # Getting back the objects:\n",
    "# with open('objs.pkl') as f:  # Python 3: open(..., 'rb')\n",
    "#     dataCite_df, scholex_df = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
