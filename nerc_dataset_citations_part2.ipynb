{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1120aec-c0e1-4987-b1a1-9219da528f21",
   "metadata": {},
   "source": [
    "### NERC dataset citations - part 2\n",
    "Takes results from nerc_dataset_citations_part1.ipynb, \n",
    "Process and merge the results.\n",
    "Produces a csv and json with details of the citations for NERC published datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13330404-5750-478b-9621-3310391248b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, json, re, datetime, os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbdade-8f90-49f1-8fd6-c3ffe4ffd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scholex_df = pd.read_csv(\"Results/Intermediate data/latest_results_scholix.csv\")\n",
    "crossref_df = pd.read_csv(\"Results/Intermediate data/latest_results_crossRef.csv\")\n",
    "datacite_df = pd.read_csv(\"Results/Intermediate data/latest_results_dataCite.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8fda5-4ca0-4a14-8325-ce7cdf189279",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove https bits from crossref df DOIs\n",
    "# remove url bit from subj_id\n",
    "crossref_doi_list = []\n",
    "for url in crossref_df['subj_id']:\n",
    "    doi = url.replace('https://doi.org/','')\n",
    "    crossref_doi_list.append(doi)\n",
    "crossref_df['subj_doi'] = crossref_doi_list\n",
    "\n",
    "# remove url bit from 'obj_id'\n",
    "crossref_doi_list = []\n",
    "for url in crossref_df['obj_id']:\n",
    "    temp = url.split('/')\n",
    "    crossref_doi_list.append(temp[3] + \"/\" + temp[4])\n",
    "crossref_df['obj_doi'] = crossref_doi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc66b0-b349-4dbc-aeb9-a85361ea83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the three dataframes make columns match\n",
    "# columns should be:\n",
    "# can add event_source, dates, publication_publisher columns later\n",
    "newColumns = ['data_publisher', 'data_doi', 'data_title', 'data_authors', 'relation_type_id', 'publication_doi', 'publication_type', 'publication_title', 'publication_authors']\n",
    "\n",
    "crossref_column_list = [crossref_df['dataset_publisher_processed'],crossref_df['obj_doi'],crossref_df['dataset_Title'],crossref_df['dataset_authors'],crossref_df['relation_type_id'],crossref_df['subj_doi'],crossref_df['subj_work_type_id'],crossref_df['pub_Title'],crossref_df['pub_authors']]\n",
    "crossref_df_newColumns = pd.concat(crossref_column_list, axis = 1)\n",
    "crossref_df_newColumns.columns = newColumns\n",
    "\n",
    "# scholex_column_list = [scholex_df[['datasetPublisher']],scholex_df[['datasetDOI']],scholex_df[['datasetTitle']],scholex_df[['datasetAuthors_processed']],scholex_df[['relationshipType']],scholex_df[['pubID']],scholex_df[['PubType']],scholex_df[['pubTitle']],scholex_df[['pubAuthors_processed']]]\n",
    "scholex_column_list = [scholex_df['datasetPublisher'],scholex_df['datasetDOI'],scholex_df['datasetTitle'],scholex_df['datasetAuthors'],scholex_df['relationshipType'],scholex_df['pubID'],scholex_df['PubType'],scholex_df['pubTitle'],scholex_df['pubAuthors_processed']]\n",
    "scholex_df_newColumns = pd.concat(scholex_column_list, axis = 1)\n",
    "scholex_df_newColumns.columns = newColumns\n",
    "\n",
    "datacite_column_list = [datacite_df['data_publisher'], datacite_df['data_doi'], datacite_df['data_title'], datacite_df['data_authors'], datacite_df['relation-type-id'], datacite_df['pub_doi'], datacite_df['publisher'], datacite_df['pub_Title'], datacite_df['pub_authors']] \n",
    "datacite_df_newColumns = pd.concat(datacite_column_list, axis = 1)\n",
    "datacite_df_newColumns.columns = newColumns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628f5db-3fea-496e-a004-205f1da3aef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create single list of data dois \n",
    "scholix_doi_list = list(scholex_df_newColumns['data_doi'])\n",
    "crossref_doi_list = list(crossref_df_newColumns['data_doi'])\n",
    "datacite_doi_list = list(datacite_df_newColumns['data_doi'])\n",
    "\n",
    "data_doi_list = scholix_doi_list + crossref_doi_list + datacite_doi_list\n",
    "\n",
    "# remove duplicates = convert to dict and back to list again auto removes dups\n",
    "data_doi_list_unique = list( dict.fromkeys(data_doi_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ce146-3f58-4a03-a018-8b1aa37036a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop through list of data dois, check pub DOI in each of crossref scholex and datacite dfs - compare result\n",
    "comparison_dicts = []\n",
    "data_doi_df = pd.DataFrame(data_doi_list_unique)\n",
    "for doi in data_doi_df[0]:\n",
    "    doi = doi.replace(\")\",\"\") # remove rogue brackets\n",
    "    scholex_indices = scholex_df_newColumns[scholex_df_newColumns.data_doi.str.match(doi)].index\n",
    "    scholex_matches = scholex_df_newColumns['publication_doi'].iloc[scholex_indices].tolist()\n",
    "    \n",
    "    crossref_indices = crossref_df_newColumns[crossref_df_newColumns.data_doi.str.match(doi)].index\n",
    "    crossref_matches = crossref_df_newColumns['publication_doi'].iloc[crossref_indices].tolist()\n",
    "    \n",
    "    datacite_indices = datacite_df_newColumns[datacite_df_newColumns.data_doi.str.match(doi)].index\n",
    "    datacite_matches = datacite_df_newColumns['publication_doi'].iloc[datacite_indices].tolist()\n",
    "    \n",
    "    combined = scholex_matches + crossref_matches + datacite_matches\n",
    "    combined_unique = list(dict.fromkeys(combined))\n",
    "    \n",
    "    inScholix_notIn_crossRef = list(set(scholex_matches) - set(crossref_matches))\n",
    "    inCrossRef_notIn_scholix = list(set(crossref_matches) - set(scholex_matches))\n",
    "    inDatacite_notIn_scholix_or_crossRef = list(set(datacite_matches) - set(scholex_matches) - set(crossref_matches))\n",
    "    \n",
    "    comparison_dicts.append({\n",
    "        'data_doi': doi,\n",
    "        'combined_unique_dois': combined_unique,\n",
    "        'scholex_pub_dois': scholex_matches,\n",
    "        'crossref_pub_dois': crossref_matches,\n",
    "        'datacite_pub_dois': datacite_matches,\n",
    "        'inScholix_notIn_crossRef':inScholix_notIn_crossRef,\n",
    "        'inCrossRef_notIn_scholix':inCrossRef_notIn_scholix,\n",
    "        'inDatacite_notIn_scholix_or_crossRef':inDatacite_notIn_scholix_or_crossRef\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c6990-107a-458f-bb57-1fa19af68554",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for combined_unique_dois create a final dataframe getting metadata  from dfs\n",
    "results = []\n",
    "for dataset in comparison_dicts:\n",
    "    for pubdoi in dataset['scholex_pub_dois']:\n",
    "        \n",
    "        # find index of this pubdoi datadoi pair in scholex_df\n",
    "        pub_indices = scholex_df_newColumns[scholex_df_newColumns.publication_doi.str.match(pubdoi)].index\n",
    "        data_indices = scholex_df_newColumns[scholex_df_newColumns.data_doi.str.match(dataset['data_doi'])].index\n",
    "        try:\n",
    "            index = list((set(pub_indices) & set(data_indices)))[0]\n",
    "        except Exception as e:\n",
    "            print(\"scholex_pub_dois\")\n",
    "            print(\"pub_indices: \", pub_indices, \"data_indices: \", data_indices)\n",
    "            print(json.dumps(dataset, indent=2))\n",
    "            continue\n",
    "        \n",
    "        results.append({\n",
    "            'data_Publisher': scholex_df_newColumns.iloc[index]['data_publisher'],\n",
    "            'data_doi':dataset['data_doi'],\n",
    "            'data_Title': scholex_df_newColumns.iloc[index]['data_title'],\n",
    "            'data_Authors': scholex_df_newColumns.iloc[index]['data_authors'],\n",
    "            'relation_type_id': scholex_df_newColumns.iloc[index]['relation_type_id'],\n",
    "            'publication_doi':pubdoi,\n",
    "            'publication_type': scholex_df_newColumns.iloc[index]['publication_type'],\n",
    "            'publication_title': scholex_df_newColumns.iloc[index]['publication_title'],\n",
    "            'publication_authors': scholex_df_newColumns.iloc[index]['publication_authors'],\n",
    "            'citation_event_source': 'Scholix'\n",
    "            })\n",
    "  \n",
    "    \n",
    "    for pubdoi in dataset['inCrossRef_notIn_scholix']:\n",
    "        # find index of this pubdoi datadoi pair in crossref_df\n",
    "        pub_indices = crossref_df_newColumns[crossref_df_newColumns.publication_doi.str.match(pubdoi)].index\n",
    "        data_indices = crossref_df_newColumns[crossref_df_newColumns.data_doi.str.match(dataset['data_doi'])].index\n",
    "        try:\n",
    "            index = list((set(pub_indices) & set(data_indices)))[0]\n",
    "        except Exception as e:\n",
    "            print(\"inCrossRef_notIn_scholix\")\n",
    "            print(\"pub_indices: \", pub_indices, \"data_indices: \", data_indices)\n",
    "            print(json.dumps(dataset, indent=2))\n",
    "            continue\n",
    "        \n",
    "        results.append({\n",
    "            'data_Publisher': crossref_df_newColumns.iloc[index]['data_publisher'],\n",
    "            'data_doi':dataset['data_doi'],\n",
    "            'data_Title': crossref_df_newColumns.iloc[index]['data_title'],\n",
    "            'data_Authors': crossref_df_newColumns.iloc[index]['data_authors'],\n",
    "            'relation_type_id': crossref_df_newColumns.iloc[index]['relation_type_id'],\n",
    "            'publication_doi':pubdoi,\n",
    "            'publication_type': crossref_df_newColumns.iloc[index]['publication_type'],\n",
    "            'publication_title': crossref_df_newColumns.iloc[index]['publication_title'],\n",
    "            'publication_authors': crossref_df_newColumns.iloc[index]['publication_authors'],\n",
    "            'citation_event_source': 'CrossRef'\n",
    "            })\n",
    "        \n",
    "        \n",
    "    for pubdoi in dataset['inDatacite_notIn_scholix_or_crossRef']:\n",
    "        # find index of this pubdoi datadoi pair in datacite_df_newColumns\n",
    "        pub_indices = datacite_df_newColumns[datacite_df_newColumns.publication_doi.str.match(pubdoi)].index\n",
    "        data_indices = datacite_df_newColumns[datacite_df_newColumns.data_doi.str.match(dataset['data_doi'])].index\n",
    "        try:\n",
    "            index = list((set(pub_indices) & set(data_indices)))[0]\n",
    "        except Exception as e:\n",
    "            print(\"inDatacite_notIn_scholix_or_crossRef\")\n",
    "            print(\"pub_indices: \", pub_indices, \"data_indices: \", data_indices)\n",
    "            print(json.dumps(dataset, indent=2))\n",
    "            continue\n",
    "        \n",
    "        results.append({\n",
    "            'data_Publisher': datacite_df_newColumns.iloc[index]['data_publisher'],\n",
    "            'data_doi':dataset['data_doi'],\n",
    "            'data_Title': datacite_df_newColumns.iloc[index]['data_title'],\n",
    "            'data_Authors': datacite_df_newColumns.iloc[index]['data_authors'],\n",
    "            'relation_type_id': datacite_df_newColumns.iloc[index]['relation_type_id'],\n",
    "            'publication_doi':pubdoi,\n",
    "            'publication_type': datacite_df_newColumns.iloc[index]['publication_type'],\n",
    "            'publication_title': datacite_df_newColumns.iloc[index]['publication_title'],\n",
    "            'publication_authors': datacite_df_newColumns.iloc[index]['publication_authors'],\n",
    "            'citation_event_source': 'DataCite'\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d6eea-7a9b-4e96-a7e1-7f3bd72c4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_citations = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ea984-8a77-4e1f-b686-3a81973c9005",
   "metadata": {},
   "source": [
    "### Get the citation string (APA format) of the publication that has cited the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1233384-6a1f-4ba9-a24a-87e842116ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TAKES A LONG TIME - hours\n",
    "# citationStrList = [] # create an empty list in which to put the citation strings\n",
    "\n",
    "# for pubDOI in data_citations['publication_doi']:\n",
    "#     if pubDOI.startswith('10.'):\n",
    "#         r = requests.get(('https://doi.org/' + pubDOI), headers={\"Accept\": \"text/x-bibliography\", \"style\": \"apa\", \"Accept-Charset\": \"utf-8\"})\n",
    "#         #print(r.status_code)\n",
    "#         citationStrList.append(r.text) # add the citation strings to the list\n",
    "#     else:\n",
    "#         citationStrList.append('not a doi')\n",
    "    \n",
    "# data_citations['PubCitationStr'] = citationStrList # add the citation string list to the Scholex df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec3e31-a2c9-4988-b5f6-86d1e65b996d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391dc49-c65a-4ee8-bbdf-049b3b77972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "citationStrList = [] # create an empty list in which to put the citation strings\n",
    "\n",
    "for pubDOI in data_citations['publication_doi']:\n",
    "    if pubDOI.startswith('10.'):\n",
    "        print(pubDOI)\n",
    "        r = requests.get((\"https://citation.crosscite.org/format?style=frontiers-of-biogeography&lang=en-GB&doi=\" + pubDOI), headers={\"Accept\":\"text/x-bibliography\", \"Accept-Charset\": \"utf-8\"})\n",
    "        print(r.status_code)\n",
    "        encoded_citation = r.text\n",
    "        # add the citation strings to the list and Decode the author names assuming UTF-8 encoding\n",
    "        citationStrList.append(encoded_citation.encode('latin1').decode('utf-8')) \n",
    "    else:\n",
    "        citationStrList.append('not a doi')\n",
    "        \n",
    "data_citations['PubCitationStr'] = citationStrList # add the citation string list to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971820cf-d6d6-4854-948a-435754689a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra requested columns\n",
    "data_citations['data_doi_url'] = 'doi.org/' + data_citations['data_doi']\n",
    "data_citations['publication_doi_url'] = 'doi.org/' + data_citations['publication_doi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84d2bd-ebd2-45cd-b90b-f3dfae6e38b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "datacite_df2 = datacite_df[['data_doi', 'publicationYear']]\n",
    "data_citations_merged = data_citations.merge(datacite_df2, left_on='data_doi', right_on='data_doi', how='left')\n",
    "data_citations_merged['publicationYear'] = data_citations_merged['publicationYear'].astype('Int64')\n",
    "data_citations_merged = data_citations_merged.fillna(np.nan).replace([np.nan], [None])\n",
    "\n",
    "data_citations_merged = data_citations_merged.drop_duplicates(subset=['data_doi', 'publication_doi'])\n",
    "# data_citations_merged\n",
    "data_citations = data_citations_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7201e8-5acd-415c-927d-0f522e32e35f",
   "metadata": {},
   "source": [
    "## Output json and csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27927f8b-07ed-4881-b914-e9793f636e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output csv file\n",
    "today = date.today()\n",
    "\n",
    "results_folder_path = \"Results/v2/\"\n",
    "file_name = 'dataCitations_allSourcesMerged_retrieved_' + (today.strftime(\"%d%m%Y\"))\n",
    "\n",
    "data_citations_csvfilename = results_folder_path + file_name + '.csv'\n",
    "data_citations.to_csv(data_citations_csvfilename, index = False)\n",
    "print(data_citations_csvfilename)\n",
    "\n",
    "# write data to 'latest_results' csv file\n",
    "latest_file_name = results_folder_path + 'latest_results' + '.csv'\n",
    "data_citations.to_csv(latest_file_name, index = False)\n",
    "\n",
    "\n",
    "# write data to 'latest_results' json file with data publisher as top level key\n",
    "latest_file_name_json = results_folder_path + 'latest_results' + '.json'\n",
    "\n",
    "# Group by 'data_Publisher' and convert the DataFrame to a nested dictionary\n",
    "nested_dict = data_citations.groupby('data_Publisher').apply(\n",
    "    lambda x: x.drop('data_Publisher', axis=1).to_dict(orient='records')\n",
    ").to_dict()\n",
    "\n",
    "# Convert the nested dictionary to a JSON object\n",
    "import json\n",
    "json_object = json.dumps(nested_dict)\n",
    "\n",
    "# Save the JSON object to a file\n",
    "with open(latest_file_name_json, 'w') as f:\n",
    "    f.write(json_object)\n",
    "    \n",
    "data_citations_jsonfilename = results_folder_path + file_name + '.json'\n",
    "\n",
    "with open(data_citations_jsonfilename, 'w') as f:\n",
    "    f.write(json_object)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
